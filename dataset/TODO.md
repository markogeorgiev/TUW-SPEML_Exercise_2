1. Research MIA attacks that fit our context:
   - No auxiliary information
   - 1/4 chance of knowing the model used to generate the synthetic data. 
     - We can consider this in our attack (trying out 4 **_assumptions_**, i.e. `Dataset_1` was generated with `model_1`, then we try an attack assuming `Dataset_1` was generated with `model_2`, ...)
2. We meet again on Wednesday (10.07.2025 at 18:00) to discuss which MIA attacks we found and would like to try out. Both of us should bring at least 4 unique approaches.
   - As a group we should have at least 6 unique MIA attacks (s.t. we can actually implement at least 3 per person).
3. Implement at least 3 MIA attacks per person, and we discuss results on Sunday (13.07.2025 at TBD_Time).
   - We might also use this time to write the structure for the report. 
4. Write the report and submit it by Wednesday (16.07.2025 at TBD_Time)1. Research MIA attacks that fit our context:
   - No auxiliary information
   - 1/4 chance of knowing the model used to generate the synthetic data. 
     - We can consider this in our attack (trying out 4 **_assumptions_**, i.e. `Dataset_1` was generated with `model_1`, then we try an attack assuming `Dataset_1` was generated with `model_2`, ...)
2. We meet again on Wednesday (09.07.2025 at 13:00) to discuss which MIA attacks we found and would like to try out. Both of us should bring at least 4 unique approaches.
   - As a group we should have at least 6 unique MIA attacks (s.t. we can actually implement at least 3 per person).
3. Implement at least 3 MIA attacks per person, and we discuss results on Sunday (13.07.2025 at TBD_Time).
   - We might also use this time to write the structure for the report. 
4. Write the report and submit it by Wednesday (16.07.2025 at TBD_Time)